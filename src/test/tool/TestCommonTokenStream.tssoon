/*
 * Copyright 2016 Terence Parr, Sam Harwell, and Burt Harris
 * All rights reserved.
 * Licensed under the BSD-3-clause license. See LICENSE file in the project root for license information.
 */

// ConvertTo-TS run at 2016-10-04T11:27:06.7679390-07:00

// import org.junit.Test;

// import static org.junit.Assert.*;

export class TestCommonTokenStream extends TestBufferedTokenStream {

	@Override
	protected createTokenStream(src: TokenSource): TokenStream {
		return new CommonTokenStream(src);
	}

	@Test testOffChannel(): void {
        let lexer: TokenSource =  // simulate input " x =34  ;\n"
            TokenSource(): new {
                let i: number =  0;
                @SuppressWarnings("serial")
                let tokens: WritableToken[] =  {
                    CommonToken(1, " "): new {{channel = Lexer.HIDDEN;}},
                    CommonToken(1, "x"): new,
                    CommonToken(1, " "): new {{channel = Lexer.HIDDEN;}},
                    CommonToken(1, "="): new,
                    CommonToken(1, "34"): new,
                    CommonToken(1, " "): new {{channel = Lexer.HIDDEN;}},
                    CommonToken(1, " "): new {{channel = Lexer.HIDDEN;}},
                    CommonToken(1, ";"): new,
                    CommonToken(1, "\n"): new {{channel = Lexer.HIDDEN;}},
                    CommonToken(Token.EOF, ""): new
                };
                @Override
                nextToken(): Token {
                    return tokens[i++];
                }
                @Override
                getSourceName(): string { return "test"; }
				@Override
				getCharPositionInLine(): number {
					return 0;
				}
				@Override
				getLine(): number {
					return 0;
				}
				@Override
				getInputStream(): CharStream {
					return null;
				}

				@Override
				getTokenFactory(): TokenFactory {
					return CommonTokenFactory.DEFAULT;
				}

				@Override
				setTokenFactory(factory: TokenFactory): void {
				}
			};

        let tokens: CommonTokenStream =  new CommonTokenStream(lexer);

        assertEquals("x", tokens.LT(1).getText()); // must skip first off channel token
        tokens.consume();
        assertEquals("=", tokens.LT(1).getText());
        assertEquals("x", tokens.LT(-1).getText());

        tokens.consume();
        assertEquals("34", tokens.LT(1).getText());
        assertEquals("=", tokens.LT(-1).getText());

        tokens.consume();
        assertEquals(";", tokens.LT(1).getText());
        assertEquals("34", tokens.LT(-1).getText());

        tokens.consume();
        assertEquals(Token.EOF, tokens.LA(1));
        assertEquals(";", tokens.LT(-1).getText());

        assertEquals("34", tokens.LT(-2).getText());
        assertEquals("=", tokens.LT(-3).getText());
        assertEquals("x", tokens.LT(-4).getText());
    }

	@Test testFetchOffChannel(): void {
		let lexer: TokenSource =  // simulate input " x =34  ; \n"
		                    // token indexes   01234 56789
			TokenSource(): new {
				let i: number =  0;
				@SuppressWarnings("serial")
				let tokens: WritableToken[] =  {
				CommonToken(1, " "): new {{channel = Lexer.HIDDEN;}}, // 0
				CommonToken(1, "x"): new,								// 1
				CommonToken(1, " "): new {{channel = Lexer.HIDDEN;}},	// 2
				CommonToken(1, "="): new,								// 3
				CommonToken(1, "34"): new,							// 4
				CommonToken(1, " "): new {{channel = Lexer.HIDDEN;}},	// 5
				CommonToken(1, " "): new {{channel = Lexer.HIDDEN;}}, // 6
				CommonToken(1, ";"): new,								// 7
				CommonToken(1, " "): new  {{channel = Lexer.HIDDEN;}},// 8
				CommonToken(1, "\n"): new {{channel = Lexer.HIDDEN;}},// 9
				CommonToken(Token.EOF, ""): new						// 10
				};
				@Override
				nextToken(): Token {
					return tokens[i++];
				}
				@Override
				getSourceName(): string { return "test"; }
				@Override
				getCharPositionInLine(): number {
					return 0;
				}
				@Override
				getLine(): number {
					return 0;
				}
				@Override
				getInputStream(): CharStream {
					return null;
				}

				@Override
				getTokenFactory(): TokenFactory {
					return CommonTokenFactory.DEFAULT;
				}

				@Override
				setTokenFactory(factory: TokenFactory): void {
				}
			};

		let tokens: CommonTokenStream =  new CommonTokenStream(lexer);
		tokens.fill();
		assertEquals(null, tokens.getHiddenTokensToLeft(0));
		assertEquals(null, tokens.getHiddenTokensToRight(0));

		assertEquals("[[@0,0:0=' ',<1>,channel=1,0:-1]]",
					 tokens.getHiddenTokensToLeft(1).toString());
		assertEquals("[[@2,0:0=' ',<1>,channel=1,0:-1]]",
					 tokens.getHiddenTokensToRight(1).toString());

		assertEquals(null, tokens.getHiddenTokensToLeft(2));
		assertEquals(null, tokens.getHiddenTokensToRight(2));

		assertEquals("[[@2,0:0=' ',<1>,channel=1,0:-1]]",
					 tokens.getHiddenTokensToLeft(3).toString());
		assertEquals(null, tokens.getHiddenTokensToRight(3));

		assertEquals(null, tokens.getHiddenTokensToLeft(4));
		assertEquals("[[@5,0:0=' ',<1>,channel=1,0:-1], [@6,0:0=' ',<1>,channel=1,0:-1]]",
					 tokens.getHiddenTokensToRight(4).toString());

		assertEquals(null, tokens.getHiddenTokensToLeft(5));
		assertEquals("[[@6,0:0=' ',<1>,channel=1,0:-1]]",
					 tokens.getHiddenTokensToRight(5).toString());

		assertEquals("[[@5,0:0=' ',<1>,channel=1,0:-1]]",
					 tokens.getHiddenTokensToLeft(6).toString());
		assertEquals(null, tokens.getHiddenTokensToRight(6));

		assertEquals("[[@5,0:0=' ',<1>,channel=1,0:-1], [@6,0:0=' ',<1>,channel=1,0:-1]]",
					 tokens.getHiddenTokensToLeft(7).toString());
		assertEquals("[[@8,0:0=' ',<1>,channel=1,0:-1], [@9,0:0='\\n',<1>,channel=1,0:-1]]",
					 tokens.getHiddenTokensToRight(7).toString());

		assertEquals(null, tokens.getHiddenTokensToLeft(8));
		assertEquals("[[@9,0:0='\\n',<1>,channel=1,0:-1]]",
					 tokens.getHiddenTokensToRight(8).toString());

		assertEquals("[[@8,0:0=' ',<1>,channel=1,0:-1]]",
					 tokens.getHiddenTokensToLeft(9).toString());
		assertEquals(null, tokens.getHiddenTokensToRight(9));
	}

	@Test
	testSingleEOF(): void {
		let lexer: TokenSource =  new TokenSource() {

			@Override
			nextToken(): Token {
				return new CommonToken(Token.EOF);
			}

			@Override
			getLine(): number {
				return 0;
			}

			@Override
			getCharPositionInLine(): number {
				return 0;
			}

			@Override
			getInputStream(): CharStream {
				return null;
			}

			@Override
			getSourceName(): string {
				return IntStream.UNKNOWN_SOURCE_NAME;
			}

			@Override
			getTokenFactory(): TokenFactory {
				throw new UnsupportedOperationException("Not supported yet.");
			}

			@Override
			setTokenFactory(factory: TokenFactory): void {
				throw new UnsupportedOperationException("Not supported yet.");
			}
		};

		let tokens: CommonTokenStream =  new CommonTokenStream(lexer);
		tokens.fill();

		assertEquals(Token.EOF, tokens.LA(1));
		assertEquals(0, tokens.index());
		assertEquals(1, tokens.size());
	}

	@Test(expected = IllegalStateException.class)
	testCannotConsumeEOF(): void {
		let lexer: TokenSource =  new TokenSource() {

			@Override
			nextToken(): Token {
				return new CommonToken(Token.EOF);
			}

			@Override
			getLine(): number {
				return 0;
			}

			@Override
			getCharPositionInLine(): number {
				return 0;
			}

			@Override
			getInputStream(): CharStream {
				return null;
			}

			@Override
			getSourceName(): string {
				return IntStream.UNKNOWN_SOURCE_NAME;
			}

			@Override
			getTokenFactory(): TokenFactory {
				throw new UnsupportedOperationException("Not supported yet.");
			}

			@Override
			setTokenFactory(factory: TokenFactory): void {
				throw new UnsupportedOperationException("Not supported yet.");
			}
		};

		let tokens: CommonTokenStream =  new CommonTokenStream(lexer);
		tokens.fill();

		assertEquals(Token.EOF, tokens.LA(1));
		assertEquals(0, tokens.index());
		assertEquals(1, tokens.size());
		tokens.consume();
	}
}
