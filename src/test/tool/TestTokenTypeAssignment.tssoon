/*
 * Copyright 2016 Terence Parr, Sam Harwell, and Burt Harris
 * All rights reserved.
 * Licensed under the BSD-3-clause license. See LICENSE file in the project root for license information.
 */

// ConvertTo-TS run at 2016-10-04T11:27:37.3374941-07:00

// import org.junit.Test;

// import static org.junit.Assert.*;

export class TestTokenTypeAssignment extends BaseTest {

	@Test
		testParserSimpleTokens(): void {
		let g: Grammar =  new Grammar(
				"parser grammar t;\n"+
				"a : A | B;\n" +
				"b : C ;");
		let rules: string =  "a, b";
		let tokenNames: string =  "A, B, C";
		checkSymbols(g, rules, tokenNames);
	}

	@Test testParserTokensSection(): void {
		let g: Grammar =  new Grammar(
				"parser grammar t;\n" +
				"tokens {\n" +
				"  C,\n" +
				"  D" +
				"}\n"+
				"a : A | B;\n" +
				"b : C ;");
		let rules: string =  "a, b";
		let tokenNames: string =  "A, B, C, D";
		checkSymbols(g, rules, tokenNames);
	}

	@Test testLexerTokensSection(): void {
		let g: LexerGrammar =  new LexerGrammar(
				"lexer grammar t;\n" +
				"tokens {\n" +
				"  C,\n" +
				"  D" +
				"}\n"+
				"A : 'a';\n" +
				"C : 'c' ;");
		let rules: string =  "A, C";
		let tokenNames: string =  "A, C, D";
		checkSymbols(g, rules, tokenNames);
	}

	@Test testCombinedGrammarLiterals(): void {
		let g: Grammar =  new Grammar(
				"grammar t;\n"+
				"a : 'begin' b 'end';\n" +
				"b : C ';' ;\n" +
				"ID : 'a' ;\n" +
				"FOO : 'foo' ;\n" +  // "foo" is not a token name
				"C : 'c' ;\n");        // nor is 'c'
		let rules: string =  "a, b";
		let tokenNames: string =  "C, FOO, ID, 'begin', 'end', ';'";
		checkSymbols(g, rules, tokenNames);
	}

	@Test testLiteralInParserAndLexer(): void {
		// 'x' is token and char in lexer rule
		let g: Grammar =  new Grammar(
				"grammar t;\n" +
				"a : 'x' E ; \n" +
				"E: 'x' '0' ;\n");

		let literals: string =  "['x']";
		let foundLiterals: string =  g.stringLiteralToTypeMap.keySet().toString();
		assertEquals(literals, foundLiterals);

		foundLiterals = g.implicitLexer.stringLiteralToTypeMap.keySet().toString();
		assertEquals("['x']", foundLiterals); // pushed in lexer from parser

		let typeToTokenName: string[] =  g.getTokenDisplayNames();
		let tokens: Set<string> =  new LinkedHashSet<String>();
		for (let t of typeToTokenName) if ( t!=null ) tokens.add(t);
		assertEquals("[<INVALID>, 'x', E]", tokens.toString());
	}

	@Test testPredDoesNotHideNameToLiteralMapInLexer(): void {
		// 'x' is token and char in lexer rule
		let g: Grammar =  new Grammar(
				"grammar t;\n" +
				"a : 'x' X ; \n" +
				"X: 'x' {true}?;\n"); // must match as alias even with pred

		assertEquals("{'x'=1}", g.stringLiteralToTypeMap.toString());
		assertEquals("{EOF=-1, X=1}", g.tokenNameToTypeMap.toString());

		// pushed in lexer from parser
		assertEquals("{'x'=1}", g.implicitLexer.stringLiteralToTypeMap.toString());
		assertEquals("{EOF=-1, X=1}", g.implicitLexer.tokenNameToTypeMap.toString());
	}

	@Test testCombinedGrammarWithRefToLiteralButNoTokenIDRef(): void {
		let g: Grammar =  new Grammar(
				"grammar t;\n"+
				"a : 'a' ;\n" +
				"A : 'a' ;\n");
		let rules: string =  "a";
		let tokenNames: string =  "A, 'a'";
		checkSymbols(g, rules, tokenNames);
	}

	@Test testSetDoesNotMissTokenAliases(): void {
		let g: Grammar =  new Grammar(
				"grammar t;\n"+
				"a : 'a'|'b' ;\n" +
				"A : 'a' ;\n" +
				"B : 'b' ;\n");
		let rules: string =  "a";
		let tokenNames: string =  "A, 'a', B, 'b'";
		checkSymbols(g, rules, tokenNames);
	}

	// T E S T  L I T E R A L  E S C A P E S

	@Test testParserCharLiteralWithEscape(): void {
		let g: Grammar =  new Grammar(
				"grammar t;\n"+
				"a : '\\n';\n");
		let literals: Set<?> =  g.stringLiteralToTypeMap.keySet();
		// must store literals how they appear in the antlr grammar
		assertEquals("'\\n'", literals.toArray()[0]);
	}

	protected checkSymbols(g: Grammar, 
								rulesStr: string,
								allValidTokensStr: string): void

	{
		let typeToTokenName: string[] =  g.getTokenNames();
		let tokens: Set<string> =  new HashSet<String>();
		for (let i = 0; i < typeToTokenName.length; i++) {
			let t: string =  typeToTokenName[i];
			if ( t!=null ) {
				if (t.startsWith(Grammar.AUTO_GENERATED_TOKEN_NAME_PREFIX)) {
					tokens.add(g.getTokenDisplayName(i));
				}
				else {
					tokens.add(t);
				}
			}
		}

		// make sure expected tokens are there
		let st: StringTokenizer =  new StringTokenizer(allValidTokensStr, ", ");
		while ( st.hasMoreTokens() ) {
			let tokenName: string =  st.nextToken();
			assertTrue("token "+tokenName+" expected, but was undefined",
					   g.getTokenType(tokenName) != Token.INVALID_TYPE);
			tokens.remove(tokenName);
		}
		// make sure there are not any others (other than <EOF> etc...)
		for (let tokenName of tokens) {
			assertTrue("unexpected token name "+tokenName,
					   g.getTokenType(tokenName) < Token.MIN_USER_TOKEN_TYPE);
		}

		// make sure all expected rules are there
		st = new StringTokenizer(rulesStr, ", ");
		let n: number =  0;
		while ( st.hasMoreTokens() ) {
			let ruleName: string =  st.nextToken();
			assertNotNull("rule "+ruleName+" expected", g.getRule(ruleName));
			n++;
		}
		//System.out.println("rules="+rules);
		// make sure there are no extra rules
		assertEquals("number of rules mismatch; expecting "+n+"; found "+g.rules.size(),
					 n, g.rules.size());

	}

}
