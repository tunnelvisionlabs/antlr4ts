/*
 * Copyright 2016 Terence Parr, Sam Harwell, and Burt Harris
 * All rights reserved.
 * Licensed under the BSD-3-clause license. See LICENSE file in the project root for license information.
 */
// ConvertTo-TS run at 2016-10-04T11:27:36.4475534-07:00

// import org.junit.Test;
// import org.junit.Ignore;

// import static org.junit.Assert.assertEquals;
// import static org.junit.Assert.assertNotNull;

export class TestTokenStreamRewriter extends BaseTest {

	/** Public default constructor used by TestRig */
	 constructor()  {
	}

	@Test testInsertBeforeIndex0(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "A : 'a';\n" +
											 "B : 'b';\n" +
											 "C : 'c';\n");
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream("abc"));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.insertBefore(0, "0");
		let result: string =  tokens.getText();
		let expecting: string =  "0abc";
		assertEquals(expecting, result);
	}

	@Test testInsertAfterLastIndex(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "A : 'a';\n" +
											 "B : 'b';\n" +
											 "C : 'c';\n");
		let input: string =  "abc";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.insertAfter(2, "x");
		let result: string =  tokens.getText();
		let expecting: string =  "abcx";
		assertEquals(expecting, result);
	}

	@Test test2InsertBeforeAfterMiddleIndex(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "A : 'a';\n" +
											 "B : 'b';\n" +
											 "C : 'c';\n");
		let input: string =  "abc";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.insertBefore(1, "x");
		tokens.insertAfter(1, "x");
		let result: string =  tokens.getText();
		let expecting: string =  "axbxc";
		assertEquals(expecting, result);
	}

	@Test testReplaceIndex0(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "A : 'a';\n" +
											 "B : 'b';\n" +
											 "C : 'c';\n");
		let input: string =  "abc";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.replace(0, "x");
		let result: string =  tokens.getText();
		let expecting: string =  "xbc";
		assertEquals(expecting, result);
	}

	@Test testReplaceLastIndex(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "A : 'a';\n" +
											 "B : 'b';\n" +
											 "C : 'c';\n");
		let input: string =  "abc";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.replace(2, "x");
		let result: string =  tokens.getText();
		let expecting: string =  "abx";
		assertEquals(expecting, result);
	}

	@Test testReplaceMiddleIndex(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "A : 'a';\n" +
											 "B : 'b';\n" +
											 "C : 'c';\n");
		let input: string =  "abc";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.replace(1, "x");
		let result: string =  tokens.getText();
		let expecting: string =  "axc";
		assertEquals(expecting, result);
	}

	@Test testToStringStartStop(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "ID : 'a'..'z'+;\n" +
											 "INT : '0'..'9'+;\n" +
											 "SEMI : ';';\n" +
											 "MUL : '*';\n" +
											 "ASSIGN : '=';\n" +
											 "WS : ' '+;\n");
		// Tokens: 0123456789
		// Input:  x = 3 * 0;
		let input: string =  "x = 3 * 0;";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.replace(4, 8, "0");
		stream.fill();
// replace 3 * 0 with 0

		let result: string =  tokens.getTokenStream().getText();
		let expecting: string =  "x = 3 * 0;";
		assertEquals(expecting, result);

		result = tokens.getText();
		expecting = "x = 0;";
		assertEquals(expecting, result);

		result = tokens.getText(Interval.of(0, 9));
		expecting = "x = 0;";
		assertEquals(expecting, result);

		result = tokens.getText(Interval.of(4, 8));
		expecting = "0";
		assertEquals(expecting, result);
	}

	@Test testToStringStartStop2(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "ID : 'a'..'z'+;\n" +
											 "INT : '0'..'9'+;\n" +
											 "SEMI : ';';\n" +
											 "ASSIGN : '=';\n" +
											 "PLUS : '+';\n" +
											 "MULT : '*';\n" +
											 "WS : ' '+;\n");
		// Tokens: 012345678901234567
		// Input:  x = 3 * 0 + 2 * 0;
		let input: string =  "x = 3 * 0 + 2 * 0;";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);

		let result: string =  tokens.getTokenStream().getText();
		let expecting: string =  "x = 3 * 0 + 2 * 0;";
		assertEquals(expecting, result);

		tokens.replace(4, 8, "0");
		stream.fill();
// replace 3 * 0 with 0
		result = tokens.getText();
		expecting = "x = 0 + 2 * 0;";
		assertEquals(expecting, result);

		result = tokens.getText(Interval.of(0, 17));
		expecting = "x = 0 + 2 * 0;";
		assertEquals(expecting, result);

		result = tokens.getText(Interval.of(4, 8));
		expecting = "0";
		assertEquals(expecting, result);

		result = tokens.getText(Interval.of(0, 8));
		expecting = "x = 0";
		assertEquals(expecting, result);

		result = tokens.getText(Interval.of(12, 16));
		expecting = "2 * 0";
		assertEquals(expecting, result);

		tokens.insertAfter(17, "// comment");
		result = tokens.getText(Interval.of(12, 18));
		expecting = "2 * 0;// comment";
		assertEquals(expecting, result);

		result = tokens.getText(Interval.of(0, 8));
		stream.fill();
// try again after insert at end
		expecting = "x = 0";
		assertEquals(expecting, result);
	}

	@Test test2ReplaceMiddleIndex(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "A : 'a';\n" +
											 "B : 'b';\n" +
											 "C : 'c';\n");
		let input: string =  "abc";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.replace(1, "x");
		tokens.replace(1, "y");
		let result: string =  tokens.getText();
		let expecting: string =  "ayc";
		assertEquals(expecting, result);
	}

	@Test test2ReplaceMiddleIndex1InsertBefore(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "A : 'a';\n" +
											 "B : 'b';\n" +
											 "C : 'c';\n");
		let input: string =  "abc";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.insertBefore(0, "_");
		tokens.replace(1, "x");
		tokens.replace(1, "y");
		let result: string =  tokens.getText();
		let expecting: string =  "_ayc";
		assertEquals(expecting, result);
	}

	@Test testReplaceThenDeleteMiddleIndex(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "A : 'a';\n" +
											 "B : 'b';\n" +
											 "C : 'c';\n");
		let input: string =  "abc";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.replace(1, "x");
		tokens.delete(1);
		let result: string =  tokens.getText();
		let expecting: string =  "ac";
		assertEquals(expecting, result);
	}

	@Test testInsertInPriorReplace(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "A : 'a';\n" +
											 "B : 'b';\n" +
											 "C : 'c';\n");
		let input: string =  "abc";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.replace(0, 2, "x");
		tokens.insertBefore(1, "0");
		let exc: Exception =  null;
		try {
			tokens.getText();
		}
		catch (IllegalArgumentException iae) {
			exc = iae;
		}
		let expecting: string =  "insert op <InsertBeforeOp@[@1,1:1='b',<2>,1:1]:\"0\"> within boundaries of previous <ReplaceOp@[@0,0:0='a',<1>,1:0]..[@2,2:2='c',<3>,1:2]:\"x\">";
		assertNotNull(exc);
		assertEquals(expecting, exc.getMessage());
	}

	@Test testInsertThenReplaceSameIndex(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "A : 'a';\n" +
											 "B : 'b';\n" +
											 "C : 'c';\n");
		let input: string =  "abc";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.insertBefore(0, "0");
		tokens.replace(0, "x");
		stream.fill();
// supercedes insert at 0
		let result: string =  tokens.getText();
		let expecting: string =  "0xbc";
		assertEquals(expecting, result);
	}

	@Test test2InsertMiddleIndex(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "A : 'a';\n" +
											 "B : 'b';\n" +
											 "C : 'c';\n");
		let input: string =  "abc";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.insertBefore(1, "x");
		tokens.insertBefore(1, "y");
		let result: string =  tokens.getText();
		let expecting: string =  "ayxbc";
		assertEquals(expecting, result);
	}

	@Test test2InsertThenReplaceIndex0(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "A : 'a';\n" +
											 "B : 'b';\n" +
											 "C : 'c';\n");
		let input: string =  "abc";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.insertBefore(0, "x");
		tokens.insertBefore(0, "y");
		tokens.replace(0, "z");
		let result: string =  tokens.getText();
		let expecting: string =  "yxzbc";
		assertEquals(expecting, result);
	}

	@Test testReplaceThenInsertBeforeLastIndex(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "A : 'a';\n" +
											 "B : 'b';\n" +
											 "C : 'c';\n");
		let input: string =  "abc";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.replace(2, "x");
		tokens.insertBefore(2, "y");
		let result: string =  tokens.getText();
		let expecting: string =  "abyx";
		assertEquals(expecting, result);
	}

	@Test testInsertThenReplaceLastIndex(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "A : 'a';\n" +
											 "B : 'b';\n" +
											 "C : 'c';\n");
		let input: string =  "abc";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.insertBefore(2, "y");
		tokens.replace(2, "x");
		let result: string =  tokens.getText();
		let expecting: string =  "abyx";
		assertEquals(expecting, result);
	}

	@Test testReplaceThenInsertAfterLastIndex(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "A : 'a';\n" +
											 "B : 'b';\n" +
											 "C : 'c';\n");
		let input: string =  "abc";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.replace(2, "x");
		tokens.insertAfter(2, "y");
		let result: string =  tokens.getText();
		let expecting: string =  "abxy";
		assertEquals(expecting, result);
	}

	@Test testReplaceRangeThenInsertAtLeftEdge(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "A : 'a';\n" +
											 "B : 'b';\n" +
											 "C : 'c';\n");
		let input: string =  "abcccba";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.replace(2, 4, "x");
		tokens.insertBefore(2, "y");
		let result: string =  tokens.getText();
		let expecting: string =  "abyxba";
		assertEquals(expecting, result);
	}

	@Test testReplaceRangeThenInsertAtRightEdge(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "A : 'a';\n" +
											 "B : 'b';\n" +
											 "C : 'c';\n");
		let input: string =  "abcccba";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.replace(2, 4, "x");
		tokens.insertBefore(4, "y");
		stream.fill(); // no effect; within range of a replace
		let exc: Exception =  null;
		try {
			tokens.getText();
		}
		catch (IllegalArgumentException iae) {
			exc = iae;
		}
		let expecting: string =  "insert op <InsertBeforeOp@[@4,4:4='c',<3>,1:4]:\"y\"> within boundaries of previous <ReplaceOp@[@2,2:2='c',<3>,1:2]..[@4,4:4='c',<3>,1:4]:\"x\">";
		assertNotNull(exc);
		assertEquals(expecting, exc.getMessage());
	}

	@Test testReplaceRangeThenInsertAfterRightEdge(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "A : 'a';\n" +
											 "B : 'b';\n" +
											 "C : 'c';\n");
		let input: string =  "abcccba";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.replace(2, 4, "x");
		tokens.insertAfter(4, "y");
		let result: string =  tokens.getText();
		let expecting: string =  "abxyba";
		assertEquals(expecting, result);
	}

	@Test testReplaceAll(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "A : 'a';\n" +
											 "B : 'b';\n" +
											 "C : 'c';\n");
		let input: string =  "abcccba";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.replace(0, 6, "x");
		let result: string =  tokens.getText();
		let expecting: string =  "x";
		assertEquals(expecting, result);
	}

	@Test testReplaceSubsetThenFetch(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "A : 'a';\n" +
											 "B : 'b';\n" +
											 "C : 'c';\n");
		let input: string =  "abcccba";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.replace(2, 4, "xyz");
		let result: string =  tokens.getText(Interval.of(0, 6));
		let expecting: string =  "abxyzba";
		assertEquals(expecting, result);
	}

	@Test testReplaceThenReplaceSuperset(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "A : 'a';\n" +
											 "B : 'b';\n" +
											 "C : 'c';\n");
		let input: string =  "abcccba";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.replace(2, 4, "xyz");
		tokens.replace(3, 5, "foo");
		stream.fill();
// overlaps, error
		let exc: Exception =  null;
		try {
			tokens.getText();
		}
		catch (IllegalArgumentException iae) {
			exc = iae;
		}
		let expecting: string =  "replace op boundaries of <ReplaceOp@[@3,3:3='c',<3>,1:3]..[@5,5:5='b',<2>,1:5]:\"foo\"> overlap with previous <ReplaceOp@[@2,2:2='c',<3>,1:2]..[@4,4:4='c',<3>,1:4]:\"xyz\">";
		assertNotNull(exc);
		assertEquals(expecting, exc.getMessage());
	}

	@Test testReplaceThenReplaceLowerIndexedSuperset(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "A : 'a';\n" +
											 "B : 'b';\n" +
											 "C : 'c';\n");
		let input: string =  "abcccba";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.replace(2, 4, "xyz");
		tokens.replace(1, 3, "foo");
		stream.fill();
// overlap, error
		let exc: Exception =  null;
		try {
			tokens.getText();
		}
		catch (IllegalArgumentException iae) {
			exc = iae;
		}
		let expecting: string =  "replace op boundaries of <ReplaceOp@[@1,1:1='b',<2>,1:1]..[@3,3:3='c',<3>,1:3]:\"foo\"> overlap with previous <ReplaceOp@[@2,2:2='c',<3>,1:2]..[@4,4:4='c',<3>,1:4]:\"xyz\">";
		assertNotNull(exc);
		assertEquals(expecting, exc.getMessage());
	}

	@Test testReplaceSingleMiddleThenOverlappingSuperset(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "A : 'a';\n" +
											 "B : 'b';\n" +
											 "C : 'c';\n");
		let input: string =  "abcba";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.replace(2, 2, "xyz");
		tokens.replace(0, 3, "foo");
		let result: string =  tokens.getText();
		let expecting: string =  "fooa";
		assertEquals(expecting, result);
	}

	@Test testCombineInserts(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "A : 'a';\n" +
											 "B : 'b';\n" +
											 "C : 'c';\n");
		let input: string =  "abc";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.insertBefore(0, "x");
		tokens.insertBefore(0, "y");
		let result: string =  tokens.getText();
		let expecting: string =  "yxabc";
		assertEquals(expecting, result);
	}

	@Test testCombine3Inserts(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "A : 'a';\n" +
											 "B : 'b';\n" +
											 "C : 'c';\n");
		let input: string =  "abc";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.insertBefore(1, "x");
		tokens.insertBefore(0, "y");
		tokens.insertBefore(1, "z");
		let result: string =  tokens.getText();
		let expecting: string =  "yazxbc";
		assertEquals(expecting, result);
	}

	@Test testCombineInsertOnLeftWithReplace(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "A : 'a';\n" +
											 "B : 'b';\n" +
											 "C : 'c';\n");
		let input: string =  "abc";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.replace(0, 2, "foo");
		tokens.insertBefore(0, "z");
		stream.fill();
// combine with left edge of rewrite
		let result: string =  tokens.getText();
		let expecting: string =  "zfoo";
		assertEquals(expecting, result);
	}

	@Test testCombineInsertOnLeftWithDelete(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "A : 'a';\n" +
											 "B : 'b';\n" +
											 "C : 'c';\n");
		let input: string =  "abc";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.delete(0, 2);
		tokens.insertBefore(0, "z");
		stream.fill();
// combine with left edge of rewrite
		let result: string =  tokens.getText();
		let expecting: string =  "z";
		stream.fill();
// make sure combo is not znull
		assertEquals(expecting, result);
	}

	@Test testDisjointInserts(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "A : 'a';\n" +
											 "B : 'b';\n" +
											 "C : 'c';\n");
		let input: string =  "abc";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.insertBefore(1, "x");
		tokens.insertBefore(2, "y");
		tokens.insertBefore(0, "z");
		let result: string =  tokens.getText();
		let expecting: string =  "zaxbyc";
		assertEquals(expecting, result);
	}

	@Test testOverlappingReplace(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "A : 'a';\n" +
											 "B : 'b';\n" +
											 "C : 'c';\n");
		let input: string =  "abcc";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.replace(1, 2, "foo");
		tokens.replace(0, 3, "bar");
		stream.fill();
// wipes prior nested replace
		let result: string =  tokens.getText();
		let expecting: string =  "bar";
		assertEquals(expecting, result);
	}

	@Test testOverlappingReplace2(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "A : 'a';\n" +
											 "B : 'b';\n" +
											 "C : 'c';\n");
		let input: string =  "abcc";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.replace(0, 3, "bar");
		tokens.replace(1, 2, "foo");
		stream.fill();
// cannot split earlier replace
		let exc: Exception =  null;
		try {
			tokens.getText();
		}
		catch (IllegalArgumentException iae) {
			exc = iae;
		}
		let expecting: string =  "replace op boundaries of <ReplaceOp@[@1,1:1='b',<2>,1:1]..[@2,2:2='c',<3>,1:2]:\"foo\"> overlap with previous <ReplaceOp@[@0,0:0='a',<1>,1:0]..[@3,3:3='c',<3>,1:3]:\"bar\">";
		assertNotNull(exc);
		assertEquals(expecting, exc.getMessage());
	}

	@Test testOverlappingReplace3(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "A : 'a';\n" +
											 "B : 'b';\n" +
											 "C : 'c';\n");
		let input: string =  "abcc";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.replace(1, 2, "foo");
		tokens.replace(0, 2, "bar");
		stream.fill();
// wipes prior nested replace
		let result: string =  tokens.getText();
		let expecting: string =  "barc";
		assertEquals(expecting, result);
	}

	@Test testOverlappingReplace4(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "A : 'a';\n" +
											 "B : 'b';\n" +
											 "C : 'c';\n");
		let input: string =  "abcc";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.replace(1, 2, "foo");
		tokens.replace(1, 3, "bar");
		stream.fill();
// wipes prior nested replace
		let result: string =  tokens.getText();
		let expecting: string =  "abar";
		assertEquals(expecting, result);
	}

	@Test testDropIdenticalReplace(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "A : 'a';\n" +
											 "B : 'b';\n" +
											 "C : 'c';\n");
		let input: string =  "abcc";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.replace(1, 2, "foo");
		tokens.replace(1, 2, "foo");
		stream.fill();
// drop previous, identical
		let result: string =  tokens.getText();
		let expecting: string =  "afooc";
		assertEquals(expecting, result);
	}

	@Test testDropPrevCoveredInsert(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "A : 'a';\n" +
											 "B : 'b';\n" +
											 "C : 'c';\n");
		let input: string =  "abc";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.insertBefore(1, "foo");
		tokens.replace(1, 2, "foo");
		stream.fill();
// kill prev insert
		let result: string =  tokens.getText();
		let expecting: string =  "afoofoo";
		assertEquals(expecting, result);
	}

	@Test testLeaveAloneDisjointInsert(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "A : 'a';\n" +
											 "B : 'b';\n" +
											 "C : 'c';\n");
		let input: string =  "abcc";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.insertBefore(1, "x");
		tokens.replace(2, 3, "foo");
		let result: string =  tokens.getText();
		let expecting: string =  "axbfoo";
		assertEquals(expecting, result);
	}

	@Test testLeaveAloneDisjointInsert2(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "A : 'a';\n" +
											 "B : 'b';\n" +
											 "C : 'c';\n");
		let input: string =  "abcc";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.replace(2, 3, "foo");
		tokens.insertBefore(1, "x");
		let result: string =  tokens.getText();
		let expecting: string =  "axbfoo";
		assertEquals(expecting, result);
	}

	@Test testInsertBeforeTokenThenDeleteThatToken(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "A : 'a';\n" +
											 "B : 'b';\n" +
											 "C : 'c';\n");
		let input: string =  "abc";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.insertBefore(2, "y");
		tokens.delete(2);
		let result: string =  tokens.getText();
		let expecting: string =  "aby";
		assertEquals(expecting, result);
	}

	// Test for https://github.com/antlr/antlr4/issues/550
	@Test 
	@Ignore
	testPreservesOrderOfContiguousInserts(): void {
		let g: LexerGrammar =  new LexerGrammar(
											 "lexer grammar T;\n"+
											 "A : 'a';\n" +
											 "B : 'b';\n" +
											 "C : 'c';\n");
		let input: string =  "aa";
		let lexEngine: LexerInterpreter =  g.createLexerInterpreter(new ANTLRInputStream(input));
		let stream: CommonTokenStream =  new CommonTokenStream(lexEngine);
		stream.fill();
		let tokens: TokenStreamRewriter =  new TokenStreamRewriter(stream);
		tokens.insertBefore(0, "<b>");
		tokens.insertAfter(0, "</b>");
		tokens.insertBefore(1, "<b>");
		tokens.insertAfter(1, "</b>");
		let result: string =  tokens.getText();
		let expecting: string =  "<b>a</b><b>a</b>"; // fails with <b>a<b></b>a</b>"
		assertEquals(expecting, result);
	}

}
