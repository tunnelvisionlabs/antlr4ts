/*
 * Copyright 2016 Terence Parr, Sam Harwell, and Burt Harris
 * All rights reserved.
 * Licensed under the BSD-3-clause license. See LICENSE file in the project root for license information.
 */

// ConvertTo-TS run at 2016-10-04T11:27:13.3679587-07:00

// import org.junit.Test;

// import static org.junit.Assert.assertEquals;
// import static org.junit.Assert.assertNull;

export class TestLexerExec extends BaseTest {
    @Test testQuoteTranslation(): void {
   		let grammar: string = 
   			"lexer grammar L;\n"+
   			"QUOTE : '\"' ;\n"; // make sure this compiles
   		let found: string =  execLexer("L.g4", grammar, "L", "\"");
   		let expecting: string = 
   			"[@0,0:0='\"',<1>,1:0]\n" +
            "[@1,1:0='<EOF>',<-1>,1:1]\n";
   		assertEquals(expecting, found);
   	}

    @Test testRefToRuleDoesNotSetTokenNorEmitAnother(): void {
   		let grammar: string = 
   			"lexer grammar L;\n"+
   			"A : '-' I ;\n" +
   			"I : '0'..'9'+ ;\n"+
   			"WS : (' '|'\\n') -> skip ;";
   		let found: string =  execLexer("L.g4", grammar, "L", "34 -21 3");
   		let expecting: string = 
   			"[@0,0:1='34',<2>,1:0]\n" +
   			"[@1,3:5='-21',<1>,1:3]\n" +
   			"[@2,7:7='3',<2>,1:7]\n" +
   			"[@3,8:7='<EOF>',<-1>,1:8]\n"; // EOF has no length so range is 8:7 not 8:8
   		assertEquals(expecting, found);
   	}

	@Test testSlashes(): void {
		let grammar: string = 
			"lexer grammar L;\n"+
			"Backslash : '\\\\';\n" +
			"Slash : '/';\n" +
			"Vee : '\\\\/';\n" +
			"Wedge : '/\\\\';\n"+
			"WS : [ \\t] -> skip;";
		let found: string =  execLexer("L.g4", grammar, "L", "\\ / \\/ /\\");
		let expecting: string = 
			"[@0,0:0='\\',<1>,1:0]\n" +
			"[@1,2:2='/',<2>,1:2]\n" +
			"[@2,4:5='\\/',<3>,1:4]\n" +
			"[@3,7:8='/\\',<4>,1:7]\n" +
			"[@4,9:8='<EOF>',<-1>,1:9]\n";
		assertEquals(expecting, found);
	}

	/**
	 * This is a regression test for antlr/antlr4#224: "Parentheses without
	 * quantifier in lexer rules have unclear effect".
	 * https://github.com/antlr/antlr4/issues/224
	 */
	@Test testParentheses(): void {
		let grammar: string = 
			"lexer grammar Demo;\n" +
			"\n" +
			"START_BLOCK: '-.-.-';\n" +
			"\n" +
			"ID : (LETTER SEPARATOR) (LETTER SEPARATOR)+;\n" +
			"fragment LETTER: L_A|L_K;\n" +
			"fragment L_A: '.-';\n" +
			"fragment L_K: '-.-';\n" +
			"\n" +
			"SEPARATOR: '!';\n";
		let found: string =  execLexer("Demo.g4", grammar, "Demo", "-.-.-!");
		let expecting: string = 
			"[@0,0:4='-.-.-',<1>,1:0]\n" +
			"[@1,5:5='!',<3>,1:5]\n" +
			"[@2,6:5='<EOF>',<-1>,1:6]\n";
		assertEquals(expecting, found);
	}

	@Test
	testNonGreedyTermination(): void {
		let grammar: string = 
			"lexer grammar L;\n"
			+ "STRING : '\"' ('\"\"' | .)*? '\"';";

		let found: string =  execLexer("L.g4", grammar, "L", "\"hi\"\"mom\"");
		assertEquals(
			"[@0,0:3='\"hi\"',<1>,1:0]\n" +
			"[@1,4:8='\"mom\"',<1>,1:4]\n" +
			"[@2,9:8='<EOF>',<-1>,1:9]\n", found);
		assertNull(stderrDuringParse);
	}

	@Test
	testNonGreedyTermination2(): void {
		let grammar: string = 
			"lexer grammar L;\n"
			+ "STRING : '\"' ('\"\"' | .)+? '\"';";

		let found: string =  execLexer("L.g4", grammar, "L", "\"\"\"mom\"");
		assertEquals(
			"[@0,0:6='\"\"\"mom\"',<1>,1:0]\n" +
			"[@1,7:6='<EOF>',<-1>,1:7]\n", found);
		assertNull(stderrDuringParse);
	}

	@Test
	testGreedyOptional(): void {
		let grammar: string = 
			"lexer grammar L;\n"
			+ "CMT : '//' .*? '\\n' CMT?;\n"
			+ "WS : (' '|'\\t')+;";

		let found: string =  execLexer("L.g4", grammar, "L", "//blah\n//blah\n");
		assertEquals(
			"[@0,0:13='//blah\\n//blah\\n',<1>,1:0]\n" +
			"[@1,14:13='<EOF>',<-1>,3:0]\n", found);
		assertNull(stderrDuringParse);
	}

	@Test
	testNonGreedyOptional(): void {
		let grammar: string = 
			"lexer grammar L;\n"
			+ "CMT : '//' .*? '\\n' CMT??;\n"
			+ "WS : (' '|'\\t')+;";

		let found: string =  execLexer("L.g4", grammar, "L", "//blah\n//blah\n");
		assertEquals(
			"[@0,0:6='//blah\\n',<1>,1:0]\n" +
			"[@1,7:13='//blah\\n',<1>,2:0]\n" +
			"[@2,14:13='<EOF>',<-1>,3:0]\n", found);
		assertNull(stderrDuringParse);
	}

	@Test
	testGreedyClosure(): void {
		let grammar: string = 
			"lexer grammar L;\n"
			+ "CMT : '//' .*? '\\n' CMT*;\n"
			+ "WS : (' '|'\\t')+;";

		let found: string =  execLexer("L.g4", grammar, "L", "//blah\n//blah\n");
		assertEquals(
			"[@0,0:13='//blah\\n//blah\\n',<1>,1:0]\n" +
			"[@1,14:13='<EOF>',<-1>,3:0]\n", found);
		assertNull(stderrDuringParse);
	}

	@Test
	testNonGreedyClosure(): void {
		let grammar: string = 
			"lexer grammar L;\n"
			+ "CMT : '//' .*? '\\n' CMT*?;\n"
			+ "WS : (' '|'\\t')+;";

		let found: string =  execLexer("L.g4", grammar, "L", "//blah\n//blah\n");
		assertEquals(
			"[@0,0:6='//blah\\n',<1>,1:0]\n" +
			"[@1,7:13='//blah\\n',<1>,2:0]\n" +
			"[@2,14:13='<EOF>',<-1>,3:0]\n", found);
		assertNull(stderrDuringParse);
	}

	@Test
	testGreedyPositiveClosure(): void {
		let grammar: string = 
			"lexer grammar L;\n"
			+ "CMT : ('//' .*? '\\n')+;\n"
			+ "WS : (' '|'\\t')+;";

		let found: string =  execLexer("L.g4", grammar, "L", "//blah\n//blah\n");
		assertEquals(
			"[@0,0:13='//blah\\n//blah\\n',<1>,1:0]\n" +
			"[@1,14:13='<EOF>',<-1>,3:0]\n", found);
		assertNull(stderrDuringParse);
	}

	@Test
	testNonGreedyPositiveClosure(): void {
		let grammar: string = 
			"lexer grammar L;\n"
			+ "CMT : ('//' .*? '\\n')+?;\n"
			+ "WS : (' '|'\\t')+;";

		let found: string =  execLexer("L.g4", grammar, "L", "//blah\n//blah\n");
		assertEquals(
			"[@0,0:6='//blah\\n',<1>,1:0]\n" +
			"[@1,7:13='//blah\\n',<1>,2:0]\n" +
			"[@2,14:13='<EOF>',<-1>,3:0]\n", found);
		assertNull(stderrDuringParse);
	}

	@Test 
	testRecursiveLexerRuleRefWithWildcardStar1(): void {
		let grammar: string = 
			"lexer grammar L;\n"+
			"CMT : '/*' (CMT | .)*? '*/' ;\n" +
			"WS : (' '|'\\n')+ ;\n"
			/*+ "ANY : .;"*/;

		let expecting: string = 
			"[@0,0:8='/* ick */',<1>,1:0]\n" +
			"[@1,9:9='\\n',<2>,1:9]\n" +
			"[@2,10:34='/* /* */\\n/* /*nested*/ */',<1>,2:0]\n" +
			"[@3,35:35='\\n',<2>,3:16]\n" +
			"[@4,36:35='<EOF>',<-1>,4:0]\n";

		// stuff on end of comment matches another rule
		let found: string =  execLexer("L.g4", grammar, "L",
						  "/* ick */\n" +
						  "/* /* */\n" +
						  "/* /*nested*/ */\n");
		assertEquals(expecting, found);
		assertNull(stderrDuringParse);
	}
	
	@Test 
	testRecursiveLexerRuleRefWithWildcardStar2(): void {
		let grammar: string = 
			"lexer grammar L;\n"+
			"CMT : '/*' (CMT | .)*? '*/' ;\n" +
			"WS : (' '|'\\n')+ ;\n"
			/*+ "ANY : .;"*/;

		// stuff on end of comment doesn't match another rule
		let expecting: string = 
			"[@0,0:8='/* ick */',<1>,1:0]\n" +
			"[@1,10:10='\\n',<2>,1:10]\n" +
			"[@2,11:36='/* /* */x\\n/* /*nested*/ */',<1>,2:0]\n" +
			"[@3,38:38='\\n',<2>,3:17]\n" +
			"[@4,39:38='<EOF>',<-1>,4:0]\n";
		let found: string =  execLexer("L.g4", grammar, "L",
						  "/* ick */x\n" +
						  "/* /* */x\n" +
						  "/* /*nested*/ */x\n");
		assertEquals(expecting, found);
		assertEquals(
			"line 1:9 token recognition error at: 'x'\n" +
			"line 3:16 token recognition error at: 'x'\n", stderrDuringParse);
	}

	@Test 
	testRecursiveLexerRuleRefWithWildcardPlus1(): void {
		let grammar: string = 
			"lexer grammar L;\n"+
			"CMT : '/*' (CMT | .)+? '*/' ;\n" +
			"WS : (' '|'\\n')+ ;\n"
			/*+ "ANY : .;"*/;

		let expecting: string = 
			"[@0,0:8='/* ick */',<1>,1:0]\n" +
			"[@1,9:9='\\n',<2>,1:9]\n" +
			"[@2,10:34='/* /* */\\n/* /*nested*/ */',<1>,2:0]\n" +
			"[@3,35:35='\\n',<2>,3:16]\n" +
			"[@4,36:35='<EOF>',<-1>,4:0]\n";

		// stuff on end of comment matches another rule
		let found: string =  execLexer("L.g4", grammar, "L",
						  "/* ick */\n" +
						  "/* /* */\n" +
						  "/* /*nested*/ */\n");
		assertEquals(expecting, found);
		assertNull(stderrDuringParse);
	}
	
	@Test 
	testRecursiveLexerRuleRefWithWildcardPlus2(): void {
		let grammar: string = 
			"lexer grammar L;\n"+
			"CMT : '/*' (CMT | .)+? '*/' ;\n" +
			"WS : (' '|'\\n')+ ;\n"
			/*+ "ANY : .;"*/;

		// stuff on end of comment doesn't match another rule
		let expecting: string = 
			"[@0,0:8='/* ick */',<1>,1:0]\n" +
			"[@1,10:10='\\n',<2>,1:10]\n" +
			"[@2,11:36='/* /* */x\\n/* /*nested*/ */',<1>,2:0]\n" +
			"[@3,38:38='\\n',<2>,3:17]\n" +
			"[@4,39:38='<EOF>',<-1>,4:0]\n";
		let found: string =  execLexer("L.g4", grammar, "L",
						  "/* ick */x\n" +
						  "/* /* */x\n" +
						  "/* /*nested*/ */x\n");
		assertEquals(expecting, found);
		assertEquals(
			"line 1:9 token recognition error at: 'x'\n" +
			"line 3:16 token recognition error at: 'x'\n", stderrDuringParse);
	}

	@Test testActionPlacement(): void {
		let grammar: string = 
			"lexer grammar L;\n"+
			"I : ({System.out.println(\"stuff fail: \" + getText());} 'a' | {System.out.println(\"stuff0: \" + getText());} 'a' {System.out.println(\"stuff1: \" + getText());} 'b' {System.out.println(\"stuff2: \" + getText());}) {System.out.println(getText());} ;\n"+
			"WS : (' '|'\\n') -> skip ;\n" +
			"J : .;\n";
		let found: string =  execLexer("L.g4", grammar, "L", "ab");
		let expecting: string = 
			"stuff0: \n" +
			"stuff1: a\n" +
			"stuff2: ab\n" +
			"ab\n" +
			"[@0,0:1='ab',<1>,1:0]\n" +
			"[@1,2:1='<EOF>',<-1>,1:2]\n";
		assertEquals(expecting, found);
	}

	@Test testGreedyConfigs(): void {
		let grammar: string = 
			"lexer grammar L;\n"+
			"I : ('a' | 'ab') {System.out.println(getText());} ;\n"+
			"WS : (' '|'\\n') -> skip ;\n" +
			"J : .;\n";
		let found: string =  execLexer("L.g4", grammar, "L", "ab");
		let expecting: string = 
			"ab\n" +
			"[@0,0:1='ab',<1>,1:0]\n" +
			"[@1,2:1='<EOF>',<-1>,1:2]\n";
		assertEquals(expecting, found);
	}

	@Test testNonGreedyConfigs(): void {
		let grammar: string = 
			"lexer grammar L;\n"+
			"I : .*? ('a' | 'ab') {System.out.println(getText());} ;\n"+
			"WS : (' '|'\\n') -> skip ;\n" +
			"J : . {System.out.println(getText());};\n";
		let found: string =  execLexer("L.g4", grammar, "L", "ab");
		let expecting: string = 
			"a\n" +
			"b\n" +
			"[@0,0:0='a',<1>,1:0]\n" +
			"[@1,1:1='b',<3>,1:1]\n" +
			"[@2,2:1='<EOF>',<-1>,1:2]\n";
		assertEquals(expecting, found);
	}

	@Test testKeywordID(): void {
		let grammar: string = 
			"lexer grammar L;\n"+
			"KEND : 'end' ;\n" + // has priority
			"ID : 'a'..'z'+ ;\n" +
			"WS : (' '|'\\n')+ ;";
		let found: string =  execLexer("L.g4", grammar, "L", "end eend ending a");
		let expecting: string = 
			"[@0,0:2='end',<1>,1:0]\n" +
			"[@1,3:3=' ',<3>,1:3]\n" +
			"[@2,4:7='eend',<2>,1:4]\n" +
			"[@3,8:8=' ',<3>,1:8]\n" +
			"[@4,9:14='ending',<2>,1:9]\n" +
			"[@5,15:15=' ',<3>,1:15]\n" +
			"[@6,16:16='a',<2>,1:16]\n" +
			"[@7,17:16='<EOF>',<-1>,1:17]\n";
		assertEquals(expecting, found);
	}

	@Test testHexVsID(): void {
		let grammar: string = 
			"lexer grammar L;\n"+
			"HexLiteral : '0' ('x'|'X') HexDigit+ ;\n"+
			"DecimalLiteral : ('0' | '1'..'9' '0'..'9'*) ;\n" +
			"FloatingPointLiteral : ('0x' | '0X') HexDigit* ('.' HexDigit*)? ;\n" +
			"DOT : '.' ;\n" +
			"ID : 'a'..'z'+ ;\n" +
			"fragment HexDigit : ('0'..'9'|'a'..'f'|'A'..'F') ;\n" +
			"WS : (' '|'\\n')+ ;";
		let found: string =  execLexer("L.g4", grammar, "L", "x 0 1 a.b a.l");
		let expecting: string = 
			"[@0,0:0='x',<5>,1:0]\n" +
			"[@1,1:1=' ',<6>,1:1]\n" +
			"[@2,2:2='0',<2>,1:2]\n" +
			"[@3,3:3=' ',<6>,1:3]\n" +
			"[@4,4:4='1',<2>,1:4]\n" +
			"[@5,5:5=' ',<6>,1:5]\n" +
			"[@6,6:6='a',<5>,1:6]\n" +
			"[@7,7:7='.',<4>,1:7]\n" +
			"[@8,8:8='b',<5>,1:8]\n" +
			"[@9,9:9=' ',<6>,1:9]\n" +
			"[@10,10:10='a',<5>,1:10]\n" +
			"[@11,11:11='.',<4>,1:11]\n" +
			"[@12,12:12='l',<5>,1:12]\n" +
			"[@13,13:12='<EOF>',<-1>,1:13]\n";
		assertEquals(expecting, found);
	}

	// must get DONE EOF
	@Test testEOFByItself(): void {
		let grammar: string = 
			"lexer grammar L;\n" +
			"DONE : EOF ;\n" +
			"A : 'a';\n";
		let found: string =  execLexer("L.g4", grammar, "L", "");
		let expecting: string = 
			"[@0,0:-1='<EOF>',<1>,1:0]\n" +
			"[@1,0:-1='<EOF>',<-1>,1:0]\n";
		assertEquals(expecting, found);
	}

	@Test testEOFSuffixInFirstRule(): void {
		let grammar: string = 
			"lexer grammar L;\n"+
			"A : 'a' EOF ;\n"+
			"B : 'a';\n"+
			"C : 'c';\n";
		let found: string =  execLexer("L.g4", grammar, "L", "");
		let expecting: string = 
			"[@0,0:-1='<EOF>',<-1>,1:0]\n";
		assertEquals(expecting, found);

		found = execLexer("L.g4", grammar, "L", "a");
		expecting =
			"[@0,0:0='a',<1>,1:0]\n" +
			"[@1,1:0='<EOF>',<-1>,1:1]\n";
		assertEquals(expecting, found);
	}

	@Test testCharSet(): void {
		let grammar: string = 
			"lexer grammar L;\n"+
			"I : '0'..'9'+ {System.out.println(\"I\");} ;\n"+
			"WS : [ \\n\\u000D] -> skip ;";
		let found: string =  execLexer("L.g4", grammar, "L", "34\r\n 34");
		let expecting: string = 
			"I\n" +
			"I\n" +
			"[@0,0:1='34',<1>,1:0]\n" +
			"[@1,5:6='34',<1>,2:1]\n" +
			"[@2,7:6='<EOF>',<-1>,2:3]\n";
		assertEquals(expecting, found);
	}

	@Test testCharSetPlus(): void {
		let grammar: string = 
			"lexer grammar L;\n"+
			"I : '0'..'9'+ {System.out.println(\"I\");} ;\n"+
			"WS : [ \\n\\u000D]+ -> skip ;";
		let found: string =  execLexer("L.g4", grammar, "L", "34\r\n 34");
		let expecting: string = 
			"I\n" +
			"I\n" +
			"[@0,0:1='34',<1>,1:0]\n" +
			"[@1,5:6='34',<1>,2:1]\n" +
			"[@2,7:6='<EOF>',<-1>,2:3]\n";
		assertEquals(expecting, found);
	}

	@Test testCharSetNot(): void {
		let grammar: string = 
			"lexer grammar L;\n"+
			"I : ~[ab \\n] ~[ \\ncd]* {System.out.println(\"I\");} ;\n"+
			"WS : [ \\n\\u000D]+ -> skip ;";
		let found: string =  execLexer("L.g4", grammar, "L", "xaf");
		let expecting: string = 
			"I\n" +
			"[@0,0:2='xaf',<1>,1:0]\n" +
			"[@1,3:2='<EOF>',<-1>,1:3]\n";
		assertEquals(expecting, found);
	}

	@Test testCharSetInSet(): void {
		let grammar: string = 
			"lexer grammar L;\n"+
			"I : (~[ab \\n]|'a') {System.out.println(\"I\");} ;\n"+
			"WS : [ \\n\\u000D]+ -> skip ;";
		let found: string =  execLexer("L.g4", grammar, "L", "a x");
		let expecting: string = 
			"I\n" +
			"I\n" +
			"[@0,0:0='a',<1>,1:0]\n" +
			"[@1,2:2='x',<1>,1:2]\n" +
			"[@2,3:2='<EOF>',<-1>,1:3]\n";
		assertEquals(expecting, found);
	}

	@Test testCharSetRange(): void {
		let grammar: string = 
			"lexer grammar L;\n"+
			"I : [0-9]+ {System.out.println(\"I\");} ;\n"+
			"ID : [a-zA-Z] [a-zA-Z0-9]* {System.out.println(\"ID\");} ;\n"+
			"WS : [ \\n\\u0009\\r]+ -> skip ;";
		let found: string =  execLexer("L.g4", grammar, "L", "34\r 34 a2 abc \n   ");
		let expecting: string = 
			"I\n" +
			"I\n" +
			"ID\n" +
			"ID\n" +
			"[@0,0:1='34',<1>,1:0]\n" +
			"[@1,4:5='34',<1>,1:4]\n" +
			"[@2,7:8='a2',<2>,1:7]\n" +
			"[@3,10:12='abc',<2>,1:10]\n" +
			"[@4,18:17='<EOF>',<-1>,2:3]\n";
		assertEquals(expecting, found);
	}

	@Test testCharSetWithMissingEndRange(): void {
		let grammar: string = 
			"lexer grammar L;\n"+
			"I : [0-]+ {System.out.println(\"I\");} ;\n"+
			"WS : [ \\n\\u000D]+ -> skip ;";
		let found: string =  execLexer("L.g4", grammar, "L", "00\r\n");
		let expecting: string = 
			"I\n" +
			"[@0,0:1='00',<1>,1:0]\n" +
			"[@1,4:3='<EOF>',<-1>,2:0]\n";
		assertEquals(expecting, found);
	}

	@Test testCharSetWithMissingEscapeChar(): void {
		let grammar: string = 
			"lexer grammar L;\n"+
			"I : [0-9]+ {System.out.println(\"I\");} ;\n"+
			"WS : [ \\u]+ -> skip ;";
		let found: string =  execLexer("L.g4", grammar, "L", "34 ");
		let expecting: string = 
			"I\n" +
			"[@0,0:1='34',<1>,1:0]\n" +
			"[@1,3:2='<EOF>',<-1>,1:3]\n";
		assertEquals(expecting, found);
	}

	@Test testCharSetWithEscapedChar(): void {
		let grammar: string = 
			"lexer grammar L;\n"+
			"DASHBRACK : [\\-\\]]+ {System.out.println(\"DASHBRACK\");} ;\n"+
			"WS : [ \\u]+ -> skip ;";
		let found: string =  execLexer("L.g4", grammar, "L", "- ] ");
		let expecting: string = 
			"DASHBRACK\n" +
			"DASHBRACK\n" +
			"[@0,0:0='-',<1>,1:0]\n" +
			"[@1,2:2=']',<1>,1:2]\n" +
			"[@2,4:3='<EOF>',<-1>,1:4]\n";
		assertEquals(expecting, found);
	}

	@Test testCharSetWithReversedRange(): void {
		let grammar: string = 
			"lexer grammar L;\n"+
			"A : [z-a9]+ {System.out.println(\"A\");} ;\n"+
			"WS : [ \\u]+ -> skip ;";
		let found: string =  execLexer("L.g4", grammar, "L", "9");
		let expecting: string = 
			"A\n" +
			"[@0,0:0='9',<1>,1:0]\n" +
			"[@1,1:0='<EOF>',<-1>,1:1]\n";
		assertEquals(expecting, found);
	}

	@Test testCharSetWithQuote(): void {
		let grammar: string = 
			"lexer grammar L;\n"+
			"A : [\"a-z]+ {System.out.println(\"A\");} ;\n"+
			"WS : [ \\n\\t]+ -> skip ;";
		let found: string =  execLexer("L.g4", grammar, "L", "b\"a");
		let expecting: string = 
			"A\n" +
			"[@0,0:2='b\"a',<1>,1:0]\n" +
			"[@1,3:2='<EOF>',<-1>,1:3]\n";
		assertEquals(expecting, found);
	}

	@Test testCharSetWithQuote2(): void {
		let grammar: string = 
			"lexer grammar L;\n"+
			"A : [\"\\\\ab]+ {System.out.println(\"A\");} ;\n"+
			"WS : [ \\n\\t]+ -> skip ;";
		let found: string =  execLexer("L.g4", grammar, "L", "b\"\\a");
		let expecting: string = 
			"A\n" +
			"[@0,0:3='b\"\\a',<1>,1:0]\n" +
			"[@1,4:3='<EOF>',<-1>,1:4]\n";
		assertEquals(expecting, found);
	}

	@Test
	testPositionAdjustingLexer(): void {
		let grammar: string =  load("PositionAdjustingLexer.g4", null);
		let input: string = 
			"tokens\n" +
			"tokens {\n" +
			"notLabel\n" +
			"label1 =\n" +
			"label2 +=\n" +
			"notLabel\n";
		let found: string =  execLexer("PositionAdjustingLexer.g4", grammar, "PositionAdjustingLexer", input);

		TOKENS: number =  4;
		LABEL: number =  5;
		IDENTIFIER: number =  6;
		let expecting: string = 
			"[@0,0:5='tokens',<" + IDENTIFIER + ">,1:0]\n" +
			"[@1,7:12='tokens',<" + TOKENS + ">,2:0]\n" +
			"[@2,14:14='{',<3>,2:7]\n" +
			"[@3,16:23='notLabel',<" + IDENTIFIER + ">,3:0]\n" +
			"[@4,25:30='label1',<" + LABEL + ">,4:0]\n" +
			"[@5,32:32='=',<1>,4:7]\n" +
			"[@6,34:39='label2',<" + LABEL + ">,5:0]\n" +
			"[@7,41:42='+=',<2>,5:7]\n" +
			"[@8,44:51='notLabel',<" + IDENTIFIER + ">,6:0]\n" +
			"[@9,53:52='<EOF>',<-1>,7:0]\n";

		assertEquals(expecting, found);
	}

	/**
	 * This is a regression test for antlr/antlr4#76 "Serialized ATN strings
	 * should be split when longer than 2^16 bytes (class file limitation)"
	 * https://github.com/antlr/antlr4/issues/76
	 */
	@Test
	testLargeLexer(): void {
		let grammar: StringBuilder =  new StringBuilder();
		grammar.append("lexer grammar L;\n");
		grammar.append("WS : [ \\t\\r\\n]+ -> skip;\n");
		for (let i = 0; i < 4000; i++) {
			grammar.append("KW").append(i).append(" : 'KW' '").append(i).append("';\n");
		}

		let input: string =  "KW400";
		let found: string =  execLexer("L.g4", grammar.toString(), "L", input);
		let expecting: string = 
			"[@0,0:4='KW400',<402>,1:0]\n" +
			"[@1,5:4='<EOF>',<-1>,1:5]\n";
		assertEquals(expecting, found);
	}

	/**
	 * This is a regression test for antlr/antlr4#687 "Empty zero-length tokens
	 * cannot have lexer commands" and antlr/antlr4#688 "Lexer cannot match
	 * zero-length tokens"
	 * https://github.com/antlr/antlr4/issues/687
	 * https://github.com/antlr/antlr4/issues/688
	 */
	@Test testZeroLengthToken(): void {
		let grammar: string = 
			"lexer grammar L;\n"+
			"\n" +
			"BeginString\n" +
			"	:	'\\'' -> more, pushMode(StringMode)\n" +
			"	;\n" +
			"\n" +
			"mode StringMode;\n" +
			"\n" +
			"	StringMode_X : 'x' -> more;\n" +
			"	StringMode_Done : -> more, mode(EndStringMode);\n" +
			"\n" +
			"mode EndStringMode;	\n" +
			"\n" +
			"	EndString : '\\'' -> popMode;\n";
		let found: string =  execLexer("L.g4", grammar, "L", "'xxx'");
		let expecting: string = 
			"[@0,0:4=''xxx'',<1>,1:0]\n" +
			"[@1,5:4='<EOF>',<-1>,1:5]\n";
		assertEquals(expecting, found);
	}
}
