/*!
 * Copyright 2016 The ANTLR Project. All rights reserved.
 * Licensed under the BSD-3-Clause license. See LICENSE file in the project root for license information.
 */

// ConvertTo-TS run at 2016-10-04T11:27:38.4472900-07:00

// import org.junit.Test;

// import static org.junit.Assert.assertEquals;

export class TestUnbufferedTokenStream extends BaseTest {
	@Test testLookahead(): void {
        let g: LexerGrammar =  new LexerGrammar(
            "lexer grammar t;\n"+
            "ID : 'a'..'z'+;\n" +
            "INT : '0'..'9'+;\n" +
            "SEMI : ';';\n" +
            "ASSIGN : '=';\n" +
            "PLUS : '+';\n" +
            "MULT : '*';\n" +
            "WS : ' '+;\n");
        // Tokens: 012345678901234567
        // Input:  x = 302;
        let input: CharStream = CharStreams.fromString("x = 302;");
        let lexEngine: LexerInterpreter =  g.createLexerInterpreter(input);
        let tokens: TokenStream =  new UnbufferedTokenStream(lexEngine);

		assertEquals("x", tokens.LT(1).text);
		assertEquals(" ", tokens.LT(2).text);
		assertEquals("=", tokens.LT(3).text);
		assertEquals(" ", tokens.LT(4).text);
		assertEquals("302", tokens.LT(5).text);
		assertEquals(";", tokens.LT(6).text);
    }

	@Test testNoBuffering(): void {
        let g: LexerGrammar =  new LexerGrammar(
            "lexer grammar t;\n"+
            "ID : 'a'..'z'+;\n" +
            "INT : '0'..'9'+;\n" +
            "SEMI : ';';\n" +
            "ASSIGN : '=';\n" +
            "PLUS : '+';\n" +
            "MULT : '*';\n" +
            "WS : ' '+;\n");
        // Tokens: 012345678901234567
        // Input:  x = 302;
        let input: CharStream = CharStreams.fromString("x = 302;");
        let lexEngine: LexerInterpreter =  g.createLexerInterpreter(input);
		let tokens: TestingUnbufferedTokenStream =  new TestingUnbufferedTokenStream(lexEngine);

		assertEquals("[[@0,0:0='x',<1>,1:0]]", tokens.getBuffer().toString());
		assertEquals("x", tokens.LT(1).text);
		tokens.consume(); // move to WS
		assertEquals(" ", tokens.LT(1).text);
		assertEquals("[[@1,1:1=' ',<7>,1:1]]", tokens.getRemainingBuffer().toString());
		tokens.consume();
		assertEquals("=", tokens.LT(1).text);
		assertEquals("[[@2,2:2='=',<4>,1:2]]", tokens.getRemainingBuffer().toString());
		tokens.consume();
		assertEquals(" ", tokens.LT(1).text);
		assertEquals("[[@3,3:3=' ',<7>,1:3]]", tokens.getRemainingBuffer().toString());
		tokens.consume();
		assertEquals("302", tokens.LT(1).text);
		assertEquals("[[@4,4:6='302',<2>,1:4]]", tokens.getRemainingBuffer().toString());
		tokens.consume();
		assertEquals(";", tokens.LT(1).text);
		assertEquals("[[@5,7:7=';',<3>,1:7]]", tokens.getRemainingBuffer().toString());
    }

	@Test testMarkStart(): void {
        let g: LexerGrammar =  new LexerGrammar(
            "lexer grammar t;\n"+
            "ID : 'a'..'z'+;\n" +
            "INT : '0'..'9'+;\n" +
            "SEMI : ';';\n" +
            "ASSIGN : '=';\n" +
            "PLUS : '+';\n" +
            "MULT : '*';\n" +
            "WS : ' '+;\n");
        // Tokens: 012345678901234567
        // Input:  x = 302;
        let input: CharStream = CharStreams.fromString("x = 302;");
        let lexEngine: LexerInterpreter =  g.createLexerInterpreter(input);
		let tokens: TestingUnbufferedTokenStream =  new TestingUnbufferedTokenStream(lexEngine);

		let m: number =  tokens.mark();
		assertEquals("[[@0,0:0='x',<1>,1:0]]", tokens.getBuffer().toString());
		assertEquals("x", tokens.LT(1).text);
		tokens.consume(); // consume x
		assertEquals("[[@0,0:0='x',<1>,1:0], [@1,1:1=' ',<7>,1:1]]", tokens.getBuffer().toString());
		tokens.consume(); // ' '
		tokens.consume(); // =
		tokens.consume(); // ' '
		tokens.consume(); // 302
		tokens.consume(); // ;
		assertEquals("[[@0,0:0='x',<1>,1:0], [@1,1:1=' ',<7>,1:1]," +
					 " [@2,2:2='=',<4>,1:2], [@3,3:3=' ',<7>,1:3]," +
					 " [@4,4:6='302',<2>,1:4], [@5,7:7=';',<3>,1:7]," +
					 " [@6,8:7='<EOF>',<-1>,1:8]]",
					 tokens.getBuffer().toString());
    }

	@Test testMarkThenRelease(): void {
        let g: LexerGrammar =  new LexerGrammar(
            "lexer grammar t;\n"+
            "ID : 'a'..'z'+;\n" +
            "INT : '0'..'9'+;\n" +
            "SEMI : ';';\n" +
            "ASSIGN : '=';\n" +
            "PLUS : '+';\n" +
            "MULT : '*';\n" +
            "WS : ' '+;\n");
        // Tokens: 012345678901234567
        // Input:  x = 302;
        let input: CharStream = CharStreams.fromString("x = 302 + 1;");
        let lexEngine: LexerInterpreter =  g.createLexerInterpreter(input);
		let tokens: TestingUnbufferedTokenStream =  new TestingUnbufferedTokenStream(lexEngine);

		let m: number =  tokens.mark();
		assertEquals("[[@0,0:0='x',<1>,1:0]]", tokens.getBuffer().toString());
		assertEquals("x", tokens.LT(1).text);
		tokens.consume(); // consume x
		assertEquals("[[@0,0:0='x',<1>,1:0], [@1,1:1=' ',<7>,1:1]]", tokens.getBuffer().toString());
		tokens.consume(); // ' '
		tokens.consume(); // =
		tokens.consume(); // ' '
		assertEquals("302", tokens.LT(1).text);
		tokens.release(m); // "x = 302" is in buffer. will kill buffer
		tokens.consume(); // 302
		tokens.consume(); // ' '
		m = tokens.mark(); // mark at the +
		assertEquals("+", tokens.LT(1).text);
		tokens.consume(); // '+'
		tokens.consume(); // ' '
		tokens.consume(); // 1
		tokens.consume(); // ;
		assertEquals("<EOF>", tokens.LT(1).text);
		// we marked at the +, so that should be the start of the buffer
		assertEquals("[[@6,8:8='+',<5>,1:8], [@7,9:9=' ',<7>,1:9]," +
					 " [@8,10:10='1',<2>,1:10], [@9,11:11=';',<3>,1:11]," +
					 " [@10,12:11='<EOF>',<-1>,1:12]]",
					 tokens.getBuffer().toString());
		tokens.release(m);
    }

	protected static class TestingUnbufferedTokenStream extends UnbufferedTokenStream {

		public TestingUnbufferedTokenStream(TokenSource tokenSource) {
			super(tokenSource);
		}

		/** For testing.  What's in moving window into token stream from
		 *  current index, LT(1) or tokens[p], to end of buffer?
		 */
		protected getRemainingBuffer(): List<? extends Token> {
			if ( n==0 ) {
				return Collections.emptyList();
			}

			return Arrays.asList(tokens).subList(p, n);
		}

		/** For testing.  What's in moving window buffer into data stream.
		 *  From 0..p-1 have been consume.
		 */
		protected getBuffer(): List<? extends Token> {
			if ( n==0 ) {
				return Collections.emptyList();
			}

			return Arrays.asList(tokens).subList(0, n);
		}

	}
}
